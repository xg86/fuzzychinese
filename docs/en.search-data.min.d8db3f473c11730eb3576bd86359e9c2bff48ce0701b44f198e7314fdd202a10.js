'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href','section']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/docs/api-documentation/',title:"API Documentation",section:"Home",content:"fuzzychinese #  [view_source]\nfuzzychinese._character_to_stroke #  [view_source]\nStroke Objects #  class Stroke(object) [view_source]\nA class to translate a chinese character into strokes.\nArguments:\n  dictionary_filepath str - default=None. File path for user provided dictionary. Default dictionary will be used if not specified.\nA valid dictionary should be a \u0026ldquo;UTF-8\u0026rdquo; encoded text file, having two columns separated by space. First column is the character and the second column is its corresponding decomposition with each char stands for each stroke. Note, the decomposition does not have to be strokes, it can be numbers or letters, or any sequence of chars you like).\nAn example dictionary:\n   Character Strokes     上 〡一一   下 一〡㇔      get_stroke #  | get_stroke(character, placeholder=\u0026#39;\u0026#39;, raise_error=False) [view_source]\nDecompose a character into strokes based on dictionary.\nWhen a character can not be decomposed, itself will be returned. If it\u0026rsquo;s not chinese, a placeholder is returned.\nArguments:\n  character str - A chinese character to be decomposed.\n  placeholder str - default = \u0026lsquo;\u0026rsquo;. Output to be used when the character is not chinese.\n  raise_error boolean - default = False. If true, raise error if a character can not be decomposed. The default action is to show warnings.\n  Returns:\n str - decomposition results.  fuzzychinese._fuzzy_chinese_match #  [view_source]\nFuzzyChineseMatch Objects #  class FuzzyChineseMatch(object) [view_source]\nThe main class for the fuzzy match\nMatch a collection of chinese words with a target list of words.\nArguments:\n  ngram_range tuple - (min_n, max_n), default=(3, 3). The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n \u0026lt;= n \u0026lt;= max_n will be used.\n  analyzer string - {\u0026lsquo;char\u0026rsquo;, \u0026lsquo;radical\u0026rsquo;, \u0026lsquo;stroke\u0026rsquo;}, default=\u0026lsquo;stroke\u0026rsquo;. Whether the feature should be made of character or stroke n-grams.\n  fit #  | fit(X) [view_source]\nLearn the words in X.\nArguments:\n X list, pd.Series, 1d np.array or 1d pd.DataFrame - An iterable yields chinese str in utf-8  Returns:\nFuzzyChinese object\nfit_transform #  | fit_transform(X, Y=None, n=3) [view_source]\nLearn the words in X and transform\nIf Y is not passed, then find similar words in the X itself . If Y is passed, for each word in Y, find the similar words in X.\nArguments:\n  X list, pd.Series, 1d np.array or 1d pd.DataFrame - An iterable yield chinese str in utf-8\n  Y list, pd.Series, 1d np.array or 1d pd.DataFrame - An iterable yield chinese str in utf-8\n  n int - top n matched to be returned\n  Returns:\n res A numpy matrix - [n_samples, n_matches]. Each row corresponds to the top n matches to the input row. Matches are sorted by descending order in similarity.  transform #  | transform(Y, n=3) [view_source]\nMatch the list of words to a target list(Y) of words.\nArguments:\n Y list, pd.Series, 1d np.array or 1d pd.DataFrame - an iterable yields chinese str in utf-8 n int - top n matched to be returned  Returns:\n res A numpy matrix - [n_samples, n_matches]. Each row corresponds to the top n matches to the input row. Matches are sorted by descending order in similarity.  get_similarity_score #  | get_similarity_score() [view_source]\nReturn the similarity score for last transform call.\nReturns:\n res A numpy matrix - [n_samples, n_matches]. Each row corresponds to the similarity score of top n matches.  get_index #  | get_index() [view_source]\nReturn the original index of the matched word.\nReturns:\n res A numpy matrix - [n_samples, n_matches]. Each row corresponds to the index of top n matches. Original index is return if exists.  compare_two_columns #  | compare_two_columns(X, Y) [view_source]\nCompare two columns and calculated similarity score for each pair on each row.\nArguments:\n  X list, pd.Series, 1d np.array or 1d pd.DataFrame - An iterable yield chinese str in utf-8\n  Y list, pd.Series, 1d np.array or 1d pd.DataFrame - Have same length as X. An iterable yield chinese str in utf-8\n  n int - top n matched to be returned\n  Returns:\n res A numpy matrix - Return two original columns and a new column for the similarity score.  fuzzychinese._character_to_radical #  [view_source]\nRadical Objects #  class Radical(object) [view_source]\nTranslate a chinese character into radicals.\nArguments:\n  dictionary_filepath str - default=None. File path for user provided dictionary. Default dictionary will be used if not specified.\nA valid dictionary should be a \u0026ldquo;UTF-8\u0026rdquo; encoded text file, having two columns separated by space. First column is the character and the second column is its corresponding decomposition with each char stands for each Radical. Note, the decomposition does not have to be radicals, it can be numbers or letters, or any sequence of chars you like).\nAn example dictionary:\n   Character Radicals     思 田心   疆 弓土畺      get_radical #  | get_radical(character, placeholder=\u0026#39;\u0026#39;, raise_error=False) [view_source]\nDecompose a character into radicals based on dictionary.\nWhen a character can not be decomposed, itself will be returned. If it\u0026rsquo;s not chinese, a placeholder is returned.\nArguments:\n  character str - A chinese character to be decomposed.\n  placeholder str - default = \u0026lsquo;\u0026rsquo;. Output to be used when the character is not chinese.\n  raise_error boolean - default = False. If true, raise error if a character can not be decomposed. The default action is to show warnings.\n  Returns:\n str - decomposition results.  fuzzychinese._utils #  [view_source]\n"}),a.add({id:1,href:'/docs/',title:"Home",section:"Home",content:"fuzzychinese #  形近词中文模糊匹配\nA simple tool to fuzzy match chinese words, particular useful for proper name matching and address matching.\n一个可以模糊匹配形近字词的小工具。对于专有名词，地址的匹配尤其有用。\n安装说明 #  pip install fuzzychinese 使用说明 #  首先使用想要匹配的字典对模型进行训练。\n然后用FuzzyChineseMatch.transform(raw_words, n) 来快速查找与raw_words的词最相近的前n个词。\n训练模型时有三种分析方式可以选择，笔划分析(stroke)，部首分析(radical)，和单字分析(char)。也可以通过调整ngram_range的值来提高模型性能。\n匹配完成后返回相似度分数，匹配的相近词语及其原有索引号。\nimport pandas as pd from fuzzychinese import FuzzyChineseMatch test_dict = pd.Series([\u0026#39;长白朝鲜族自治县\u0026#39;,\u0026#39;长阳土家族自治县\u0026#39;,\u0026#39;城步苗族自治县\u0026#39;,\u0026#39;达尔罕茂明安联合旗\u0026#39;,\u0026#39;汨罗市\u0026#39;]) raw_word = pd.Series([\u0026#39;达茂联合旗\u0026#39;,\u0026#39;长阳县\u0026#39;,\u0026#39;汩罗市\u0026#39;]) assert(\u0026#39;汩罗市\u0026#39;!=\u0026#39;汨罗市\u0026#39;) # They are not the same! fcm = FuzzyChineseMatch(ngram_range=(3, 3), analyzer=\u0026#39;stroke\u0026#39;) fcm.fit(test_dict) top2_similar = fcm.transform(raw_word, n=2) res = pd.concat([ raw_word, pd.DataFrame(top2_similar, columns=[\u0026#39;top1\u0026#39;, \u0026#39;top2\u0026#39;]), pd.DataFrame( fcm.get_similarity_score(), columns=[\u0026#39;top1_score\u0026#39;, \u0026#39;top2_score\u0026#39;]), pd.DataFrame( fcm.get_index(), columns=[\u0026#39;top1_index\u0026#39;, \u0026#39;top2_index\u0026#39;])], axis=1)     top1 top2 top1_score top2_score top1_index top2_index     达茂联合旗 达尔罕茂明安联合旗 长白朝鲜族自治县 0.824751 0.287237 3 0   长阳县 长阳土家族自治县 长白朝鲜族自治县 0.610285 0.475000 1 0   汩罗市 汨罗市 长白朝鲜族自治县 1.000000 0.152093 4 0    其他功能 #    直接使用Stroke, Radical进行汉字分解。\nstroke = Stroke() radical = Radical() print(\u0026#34;像\u0026#34;, stroke.get_stroke(\u0026#34;像\u0026#34;)) print(\u0026#34;像\u0026#34;, radical.get_radical(\u0026#34;像\u0026#34;)) 像 ㇒〡㇒㇇〡㇕一㇒㇁㇒㇒㇒㇏ 像 人象   使用FuzzyChineseMatch.compare_two_columns(X, Y)对每一行的两个词进行比较，获得相似度分数。\n  详情请参见说明文档.\n  致谢 #  拆字数据来自于 漢語拆字字典 by 開放詞典網。\nInstallation #  pip install fuzzychinese Quickstart #  First train a model with the target list of words you want to match to.\nThen use FuzzyChineseMatch.transform(raw_words, n) to find top n most similar words in the target for your raw_words .\nThere are three analyzers to choose from when training a model: stroke, radical, and char. You can also change ngram_range to fine-tune the model.\nAfter the matching, similarity score, matched words and its corresponding index are returned.\nfrom fuzzychinese import FuzzyChineseMatch test_dict = pd.Series([\u0026#39;长白朝鲜族自治县\u0026#39;,\u0026#39;长阳土家族自治县\u0026#39;,\u0026#39;城步苗族自治县\u0026#39;,\u0026#39;达尔罕茂明安联合旗\u0026#39;,\u0026#39;汨罗市\u0026#39;]) raw_word = pd.Series([\u0026#39;达茂联合旗\u0026#39;,\u0026#39;长阳县\u0026#39;,\u0026#39;汩罗市\u0026#39;]) assert(\u0026#39;汩罗市\u0026#39;!=\u0026#39;汨罗市\u0026#39;) # They are not the same! fcm = FuzzyChineseMatch(ngram_range=(3, 3), analyzer=\u0026#39;stroke\u0026#39;) fcm.fit(test_dict) top2_similar = fcm.transform(raw_word, n=2) res = pd.concat([ raw_word, pd.DataFrame(top2_similar, columns=[\u0026#39;top1\u0026#39;, \u0026#39;top2\u0026#39;]), pd.DataFrame( fcm.get_similarity_score(), columns=[\u0026#39;top1_score\u0026#39;, \u0026#39;top2_score\u0026#39;]), pd.DataFrame( fcm.get_index(), columns=[\u0026#39;top1_index\u0026#39;, \u0026#39;top2_index\u0026#39;])], axis=1)     top1 top2 top1_score top2_score top1_index top2_index     达茂联合旗 达尔罕茂明安联合旗 长白朝鲜族自治县 0.824751 0.287237 3 0   长阳县 长阳土家族自治县 长白朝鲜族自治县 0.610285 0.475000 1 0   汩罗市 汨罗市 长白朝鲜族自治县 1.000000 0.152093 4 0    Other use #    Directly use Stroke, Radical to decompose Chinese character into strokes or radicals.\nstroke = Stroke() radical = Radical() print(\u0026#34;像\u0026#34;, stroke.get_stroke(\u0026#34;像\u0026#34;)) print(\u0026#34;像\u0026#34;, radical.get_radical(\u0026#34;像\u0026#34;)) 像 ㇒〡㇒㇇〡㇕一㇒㇁㇒㇒㇒㇏ 像 人象   Use FuzzyChineseMatch.compare_two_columns(X, Y) to compare the pair of words in each row to get similarity score.\n  See documentation for details.\n  Credits #  Data for Chinese radicals are from 漢語拆字字典 by 開放詞典網.\n"})})()